# VisCo Attack Configuration

# Model settings
models:
  # Target VLM for attack
  target_model:
    type: "qwen-vl"  # Options: qwen-vl, internvl
    model_path: "/mnt/pfs/share/pretrained_model/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/68156fd997cdc9f710620466735af49862bb81f6/"
    device: "cuda"  # Options: cuda, cpu, auto
    max_tokens: 2048
    temperature: 0.0
    trust_remote_code: true
  
  # Auxiliary VLM for description
  aux_vlm:
    type: "qwen-vl"
    model_path: "/mnt/pfs/share/pretrained_model/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/68156fd997cdc9f710620466735af49862bb81f6/"
    device: "cuda"  # Options: cuda, cpu, auto
    max_tokens: 1024
    temperature: 0.7
    trust_remote_code: true
  
  # SDXL for auxiliary image generation
  sdxl:
    model_path: "/mnt/pfs/share/pretrained_model/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0/snapshots/462165984030d82259a11f4367a4eed129e94a7b/"
    device: "cuda"  # Options: cuda, cpu, mps (for Mac)
    num_inference_steps: 30
    guidance_scale: 7.5
    # Optional: Set cache directory for models
    # cache_dir: null  # null uses default ~/.cache/huggingface/hub

# Attack strategies configuration
strategies:
  VS:  # Image-Grounded Scenario Simulation
    num_rounds: 3
    use_auxiliary_image: true
    scenario_type: "novel_writing"  # novel_writing, filmmaking, research
  
  VM:  # Image Multi-Perspective Analysis
    num_rounds: 3
    use_auxiliary_image: false
    perspectives: ["safety", "risk", "vulnerability"]
  
  VI:  # Iterative Image Interrogation
    num_rounds: 3
    use_auxiliary_image: false
    interrogation_depth: "deep"  # shallow, medium, deep
  
  VH:  # Exploiting Image Hallucination
    num_rounds: 3
    use_auxiliary_image: true
    hallucination_type: "news_report"  # news_report, related_scene, ambiguous

# Prompt refinement settings
refinement:
  max_iterations: 3
  enable_toxicity_obfuscation: true
  enable_semantic_alignment: true

# Logging
logging:
  level: "INFO"
  save_context: true
  save_responses: true
  output_dir: "outputs/"



